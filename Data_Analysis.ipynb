{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id =6></a><br>\n",
    "The project is outlined as following:\n",
    " \n",
    " - [THE DATA](#1)\n",
    " \n",
    " - [ADDING NEW COLUMNS](#2)\n",
    " \n",
    " - [GATHERING EVENTS](#3)\n",
    " \n",
    " - [FINDING TRAJECTORIES](#4)\n",
    " \n",
    " - [VISUALIZING THE EVENTS](#5)\n",
    " - [DETECTOR MATRIX](#7)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><a id =1></a><br> THE DATA: Calibration run 260 / Real Measurement run 333\n",
    "\n",
    "\n",
    "In this project, we analyze the data obtained through a set of particle detectors. The detectors consist on four layers of cells fulls of a gas. Each of the cells is traversed by an anodic cable in its middle. When a particle traverses the gas, it ionizes it, with the ions being then attracted towards the cable. The cell then emmits a signal when the ions reach the cable. \\\n",
    "The ions can be considered to travel at a constat drift velocity $v_d$ towards the cable. The impact possition in a cell $x$ can be expressed as\n",
    "    \n",
    "    \n",
    "$$\n",
    "x = v_d (t - t_0),\n",
    "$$\n",
    "    \n",
    "being $t_0$ a pedestal time and $t$ the time recorded by the detector. As the maximum drift time  $T_{Max} = \\frac{L}{2 v_d} = 390$ ns ($L=42$ mm is the lenght of the cell) is a known country, t0 can be calculated. This will be explained later.    \n",
    "\\\n",
    "The data obtained are encoded in a CSV file. The way we can interpret its content is exlained as it is needed. It is the goal of this project to analyze these data so that we can track the trajectories of the particles through them. More specifically, the tasks to do are:\n",
    "    \n",
    "    -Grouping the data into events corresponding to a particle hitting the detector\n",
    "    -Obtain and plot the drift times\n",
    "    \n",
    "This was done for both a calibration run and for a the data obtained in a real experiment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from os import listdir\n",
    "from os.path import isfile, join, getsize\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string)) # for markdown purposes\n",
    "from numba import vectorize, int64, int32, jit, njit, cuda, float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# <a id =1></a><br> THE DATA: Calibration run 260 / Real Measurement run 333\n",
    "[Content Outline](#6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Set as FALSE for Calibration run \n",
    "REAL_DATA = True\n",
    "\n",
    "# We limit the amount of data we are accepting \n",
    "if REAL_DATA:\n",
    "    mypath = '../data/Run000333/'\n",
    "else:\n",
    "    mypath = '../data/Run000260/'\n",
    "\n",
    "max_mb = 65 # maximum size of data in mb to read in\n",
    "files = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "mb = 0\n",
    "for i in range(len(files)):\n",
    "    mb += getsize(files[i])/1024**2 # getsize returns size in bytes\n",
    "    if mb >= max_mb:\n",
    "        files = files[:(i-1)]\n",
    "        break\n",
    "\n",
    "# Load the data\n",
    "data = pd.concat([pd.read_csv(file) for file in files], axis = 0)\n",
    "data.reset_index(inplace=True, drop=True) #This resets the index from 0 to onwards\n",
    "# data = pd.read_csv(files[0])\n",
    "\n",
    "#Let's drop the column named 'HEAD'\n",
    "data.drop('HEAD', inplace=True, axis=1) # We remove the 'HEAD', inplace = True because we return nothing\n",
    "\n",
    "# We print the description\n",
    "printmd('## DESCRIPTION OF THE DATA')\n",
    "print('Used files:', '\\n', files, '\\n') # To check which files are read\n",
    "print(data.info())\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of the first 5 entries of the file\n",
    "printmd('## THE DATAFRAME')\n",
    "printmd('The dataframe below presents the first 10 hits as presented in the raw data')\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "df_0 = data[data['FPGA']==0]\n",
    "df_1 = data[data['FPGA']==1]\n",
    "\n",
    "max_channel = data['TDC_CHANNEL'].max()\n",
    "df_0.hist('TDC_CHANNEL', ax=ax1, bins=max_channel)#, range=(137,138))\n",
    "df_1.hist('TDC_CHANNEL', ax=ax2, bins=max_channel)#, range=(137,138))\n",
    "ax1.set_title('FPGA 0')\n",
    "ax2.set_title('FPGA 1')\n",
    "\n",
    "printmd('## HISTOGRAM OF HITS PER CHANNEL')\n",
    "plt.show()\n",
    "printmd('#### There are a lot of hits falling under the mean time trigger')\n",
    "# Remark: There is a lot of data in the trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id =2></a><br>  ADDING NEW COLUMNS: TIME, DETECTOR, LAYER, AND CELL\n",
    " [Content Outline](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONSTANTS: TRIGGER CHANNELS AND TMAX, L, Vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = 137  # Scintillator trigger channel 1\n",
    "st2 = 138  # Scintillator trigger channel 2\n",
    "mtt = 139  # Mean-time trigger channel\n",
    "T_M = 390  #(maximum drift time in ns)\n",
    "L = 42  # (lenght of the cell in mm)\n",
    "v_d = L/(2*T_M)  # (constant drift velocity in mm/ns)\n",
    "\n",
    "# We set the detector column to display -1 for trigger and detector number\n",
    "data['detector'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## TIME COLUMN\n",
    " \n",
    " Let's add a column to the existing data.\n",
    "\n",
    "This new column will be the time measurements(ns). The time measurement in nanoseconds is given by:\n",
    "\n",
    "```python\n",
    " data['time']=data['ORBIT_CNT']*2564*25+data['BX_COUNTER']*25+data['TDC_MEAS']*25/30\n",
    "```\n",
    " \n",
    "Now, the rate of passage of particles through the detector was rather limited, i.e. the chance to get two particle within the same orbit is extremely small. Therefore we can drop the orbit part of the formula yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time'] = data['BX_COUNTER']*25 + data['TDC_MEAS']*25/30\n",
    "\n",
    "# We have added a new time column to the data. The first 5 rows are\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual time taken by the ionization to reach the anodic wire (drift time) is proportional to the distance:\n",
    "\n",
    "$$\n",
    "x = v_d t_i= v_d(t_R-t_0)\n",
    "$$\n",
    "\n",
    "where $v_d$ is the constant drift velocity, $t_R$ is the time recorded by the electronics and $t_0$ is a time pedestal which needs to be determined for every particles crossing the detector (the drift time is $t_R-t_0$). This is possible thanks to the geometry of the layers, more precisely by the fact that they are staggered by exactly half a cell. \n",
    "\n",
    "To compute the constant $t_0$, which is different for every event, we can use the following relation:\n",
    "\n",
    "$$T_{MAX}=\\frac{t_{1}+t_{3}}{2}+t_{2}$$\n",
    "\n",
    "where $t_1 = t_{1'}-t_0$, $t_2 = t_{2'}-t_0$ and $t_3 = t_{3'}-t_0$, are the drift times of those three cells and $t_{i'}$ is the time measurement of the respective cell. The drift times can be calculated in this way because $t_0$ is essentially the same for each cell in one event, because the particle velocity of the muons(?) is much higher than the drift velocity of the electrons. Then the relation becomes:\n",
    "\n",
    "$$T_{MAX}=\\frac{t_{1'}-t_0+t_{3'}-t_0}{2}+t_{2'}-t_0$$\n",
    "\n",
    "from which we get:\n",
    "\n",
    "$$t_0=\\frac{t_{1'}+t_{3'}+2t_{2'}-2T_{MAX}}{4}$$\n",
    "\n",
    "Finally we notice that $t_{1'}$, $t_{2'}$, $t_{3'}$ are the times recorded by each cell, which are already available in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETECTOR, LAYER, AND CELL COLUMNS\n",
    "\n",
    "Before processing the dataset, we have to create some missing columns, in fact the DataFrame with the events must contain the following information:\n",
    "* CHAMBER, which is the Detector number. The data to be analyzed have been gathered by a series of (4) particle detectors: [1-4]\n",
    "* LAYER.  Such detectors were composed by four layers of cells: [1-4];\n",
    "* CELL, which is in the number of the cell.  The actual detector has 16 cells per layer: [1-16]\n",
    "* POSTION, which is the position where a particle traverses the cell [0-21] (in mm. The maximum 21 mm value corresponds to the position of the anodic wire to where the particles travel. In this case the left-right ambiguity is NOT resolved). \n",
    "\n",
    "\n",
    "\n",
    "![(Picture of detector configuration)](./Detector.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The channels are mapped to the four detectors in the following ways:\n",
    "\n",
    "* Detector 1 $\\rightarrow$ FPGA 0, TDC_CHANNEL in [1-64]\n",
    "* Detector 2 $\\rightarrow$ FPGA 0, TDC_CHANNEL in [65-128]\n",
    "* Detector 3 $\\rightarrow$ FPGA 1, TDC_CHANNEL in [1-64]\n",
    "* Detector 4 $\\rightarrow$ FPGA 1, TDC_CHANNEL in [65-128]\n",
    "\n",
    "Notice that since we have 4 layers with 16 cells per layes, each detector will have 64 cells. Therefore, we can assume that the TDC_CHANNEL is a label for all the cells in the chamber.\n",
    "\n",
    "Even though not used as such, an external trigger was present anyway. When it fired a special 64 bit word (a row in the csv file) were produced enconding the trigger information, i.e. the timing at which it occurred and which of the kind of trigger fired. More precisely:\n",
    "\n",
    "* Mean-time trigger: TDC_CHANNEL=139\n",
    "* Scintillator trigger: TDC_CHANNEL=137 or 138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding detector, layer and cell columns \n",
    "\n",
    "@vectorize([int64(int64, int64)])\n",
    "def giveDetector(fpga, channel):\n",
    "    if channel > 128:\n",
    "        return -1\n",
    "\n",
    "    channel -= 1\n",
    "    return fpga*2 + 1 + channel // 64\n",
    "\n",
    "@vectorize([int64(int64)])\n",
    "def giveLayer(channel):\n",
    "    if channel > 128:\n",
    "        return -1\n",
    "\n",
    "    layer_map = {0 : 1,\n",
    "                 1 : 4,\n",
    "                 2 : 2,\n",
    "                 3 : 3}\n",
    "\n",
    "    cell_index = channel % 64\n",
    "    layer = layer_map[cell_index % 4]\n",
    "    \n",
    "    return layer\n",
    "\n",
    "@vectorize([int64(int64)])\n",
    "def giveCell(channel):\n",
    "    if channel > 128:\n",
    "        return -1\n",
    "\n",
    "    channel -= 1\n",
    "    cell_index = channel % 64\n",
    "    cell = cell_index // 4 + 1\n",
    "\n",
    "    return cell\n",
    "\n",
    "# Test of functions\n",
    "if __name__ == '__main__':\n",
    "    first_cell_of_layer = 67\n",
    "    a = np.arange(first_cell_of_layer,first_cell_of_layer+16*4,4)\n",
    "    print(list(zip(giveDetector(0,a), giveLayer(a), giveCell(a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculation of detector, layer & cell according to the previous functions\n",
    "data['detector'] = giveDetector(data['FPGA'], data['TDC_CHANNEL'])\n",
    "data['layer'] = giveLayer(data['TDC_CHANNEL'])\n",
    "data['cell'] = giveCell(data['TDC_CHANNEL'])\n",
    "\n",
    "display(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id =3></a><br> FINDING EVENTS \n",
    " [Content Outline](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trigger dataset is formed by applying a mask to the original data in order to isolate the hits that correspond to the TDC_CHANNEL 139. Similar lines of code are presented for the two other trigger channels, scintillator 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_mtt = data.loc[data['TDC_CHANNEL']==mtt, ['ORBIT_CNT','time']]\n",
    "trigger_st = data.loc[(data['TDC_CHANNEL']==st1) | (data['TDC_CHANNEL']==st2), ['ORBIT_CNT','time']]\n",
    "\n",
    "display(trigger_mtt.head())\n",
    "if not trigger_st.empty:\n",
    "    display(trigger_st.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the .isin() function, the orbits found in trigger_mtt data is isolated from the original dataset to produce the 'events' dataset because, supposedly, **one event corresponds to one common orbit.** The next lines of code sorts the by orbits and reindexed to present the data for each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#.isin function compares the two arrays and takes only the orbits that are found in the trigger\n",
    "events_mtt = data.loc[data['ORBIT_CNT'].isin(trigger_mtt['ORBIT_CNT'])]\n",
    "events_st = data.loc[data['ORBIT_CNT'].isin(trigger_st['ORBIT_CNT'])]\n",
    "\n",
    "def create_events(df):\n",
    "    events = df.copy(deep=False)\n",
    "    # We remove the events that are in channels above 128\n",
    "    events = events[events['TDC_CHANNEL'] <= 128]\n",
    "\n",
    "    # We now group by orbit\n",
    "    events['event'] = events.groupby('ORBIT_CNT').ngroup()+1\n",
    "\n",
    "    # Common orbits correspond to a single event\n",
    "    events.set_index(['event', events.index], inplace=True) # We make the events column an index\n",
    "    events.rename_axis(('event','index'), inplace=True)\n",
    "    events.sort_values(['ORBIT_CNT','detector','layer','cell'], inplace=True) # We sort according to these categories\n",
    "\n",
    "    printmd('## EVENTS DATAFRAME')\n",
    "    display(events.head(4))\n",
    "    \n",
    "    return events\n",
    "\n",
    "events_mtt = create_events(events_mtt)\n",
    "display(events_mtt.head(5))\n",
    "if not trigger_st.empty:\n",
    "    events_st = create_events(events_st)\n",
    "    display(events_st.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id =4></a><br> FINDING THE TRAJECTORIES, computing t0\n",
    " [Content Outline](#6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTrajectories(df):\n",
    "    data = df.copy(deep=False)\n",
    "    data['t0_1'] = 0\n",
    "    data['t0_2'] = 0\n",
    "    for i in data.index.get_level_values(0).unique():\n",
    "        present_detectors = data.loc[i,'detector'].unique()\n",
    "        ev = data.loc[i].copy(deep=False)\n",
    "        \n",
    "        for det in present_detectors:\n",
    "            sub_ev = ev.loc[ev['detector'] == det].copy(deep=False)\n",
    "            for l in range(1,4):\n",
    "                fst_layer = sub_ev.loc[sub_ev['layer'] == l, 'cell']\n",
    "                sec_layer = sub_ev.loc[sub_ev['layer'] == l+1, 'cell']\n",
    "\n",
    "                # Find successor for each cell in layer\n",
    "                if l % 2 == 0:\n",
    "                    successor_mask = fst_layer.isin(sec_layer) | fst_layer.isin(sec_layer+1)\n",
    "                else:\n",
    "                    successor_mask = fst_layer.isin(sec_layer) | fst_layer.isin(sec_layer-1)\n",
    "                \n",
    "                # Drop whole sub_event if the current layer is completely empty\n",
    "                if successor_mask.sum() == 0:\n",
    "                    sub_ev['t0_1'] = np.nan\n",
    "                    sub_ev['t0_2'] = np.nan\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    # Drop rows where no successor was found\n",
    "                    sub_ev.loc[(successor_mask==False).index, 't0_1'] = np.nan\n",
    "                    sub_ev.loc[(successor_mask==False).index, 't0_2'] = np.nan\n",
    "\n",
    "            na_mask = sub_ev['t0_1'].notna()\n",
    "            if na_mask.sum() > 0:\n",
    "                sub_ev.loc[na_mask,'t0_1'] = 0.5*(0.5*(sub_ev.loc[(sub_ev.loc[na_mask, 'layer']==1).index, 't0_1'].iloc[0]+\n",
    "                                                        sub_ev.loc[(sub_ev.loc[na_mask, 'layer']==3).index, 't0_1'].iloc[0])+\n",
    "                                                  sub_ev.loc[(sub_ev.loc[na_mask, 'layer']==2).index, 't0_1'].iloc[0])\n",
    "                sub_ev.loc[na_mask, 't0_2'] = 0.5*(0.5*(sub_ev.loc[(sub_ev.loc[na_mask, 'layer']==2).index, 't0_1'].iloc[0]+\n",
    "                                                        sub_ev.loc[(sub_ev.loc[na_mask, 'layer']==4).index, 't0_1'].iloc[0])+\n",
    "                                                   sub_ev.loc[(sub_ev.loc[na_mask, 'layer']==3).index, 't0_1'].iloc[0])\n",
    "\n",
    "    return data\n",
    "            \n",
    "\n",
    "# np.isin or in function of numpy/python is not supported by numba\n",
    "# That's why we make a new .isin function to be able to use the @njit decorator\n",
    "@njit\n",
    "def myIsin(array_a, array_b):\n",
    "    result = np.zeros(len(array_a), dtype=np.bool_)\n",
    "    for i,a in enumerate(array_a):\n",
    "        for j,b in enumerate(array_b):\n",
    "            if a == b:\n",
    "                result[i] = True\n",
    "                break\n",
    "    return result\n",
    "\n",
    "\n",
    "@njit\n",
    "def findTrajectories_np(data, inds, columns): # data, index, columns??\n",
    "    det_ind, lay_ind, cel_ind, time_ind, t0_1_ind, t0_2_ind = columns #detector, layer, cel, time, 1t0, 2t0 are the columns # use old version???\n",
    "    #np.roll (array, shift, axis)  #elements of the input array are being shifted\n",
    "    ev_locs = np.where(inds - np.roll(inds,1)!=0)[0]  #np.where(condition,[x,y]) return elements chosen from x or y depending on condition.\n",
    "    ev_locs = np.append(ev_locs, [len(inds)])\n",
    "\n",
    "    for i in range(len(ev_locs)-1):\n",
    "    \n",
    "        ev = data[ev_locs[i]:ev_locs[i+1]]\n",
    "\n",
    "        # Every row registered in same detector?\n",
    "        if np.unique(ev[:,det_ind]).size != 1:\n",
    "            sub_ev_locs = np.where(ev[:,det_ind]-np.roll(ev[:,det_ind],1)!=0)[0]\n",
    "            sub_ev_locs = np.append(sub_ev_locs, [len(ev[:,det_ind])])\n",
    "\n",
    "        else:\n",
    "            sub_ev_locs = np.array([0,len(ev[:,det_ind])])\n",
    "\n",
    "        for j in range(len(sub_ev_locs)-1):\n",
    "            sub_ev = ev[sub_ev_locs[j]:sub_ev_locs[j+1]]\n",
    "\n",
    "            for l in range(1,4):\n",
    "                fst_layer = sub_ev[sub_ev[:,lay_ind]==l,cel_ind]\n",
    "                sec_layer = sub_ev[sub_ev[:,lay_ind]==l+1,cel_ind]\n",
    "\n",
    "                # Find successor for each cell in layer\n",
    "                if l % 2 == 0:\n",
    "                    successor_mask = myIsin(fst_layer, sec_layer) | myIsin(fst_layer, sec_layer+1)\n",
    "                else:\n",
    "                    successor_mask = myIsin(fst_layer, sec_layer) | myIsin(fst_layer, sec_layer-1)\n",
    "\n",
    "                # Drop whole sub_event if the current layer is completely empty\n",
    "                if np.any(successor_mask) == False:\n",
    "                    sub_ev[:,t0_1_ind] = np.nan\n",
    "                    sub_ev[:,t0_2_ind] = np.nan\n",
    "                    break\n",
    "\n",
    "                # Else mark rows where no successor was found\n",
    "                # if one cell was found with no successor\n",
    "                elif np.all(successor_mask) == False: # False has to be np.array([False]) so that numba broadcasts\n",
    "                    idx = np.nonzero(successor_mask==np.array([False]))[0] + np.nonzero(sub_ev[:,lay_ind]==l)[0][0]\n",
    "                    sub_ev[idx,t0_1_ind] = np.nan\n",
    "                    sub_ev[idx,t0_2_ind] = np.nan\n",
    "\n",
    "            # Compute t0 if a trajectory was found\n",
    "            mask = ~np.isnan(sub_ev[:,t0_1_ind]) # mask where values are numbers and not NaN\n",
    "            if np.any(mask) == True:\n",
    "                sub_ev[mask,t0_1_ind] = 0.5*(0.5*(sub_ev[sub_ev[mask,lay_ind]==1,time_ind][0]+\n",
    "                                           sub_ev[sub_ev[mask,lay_ind]==3,time_ind][0])+\n",
    "                                      sub_ev[sub_ev[mask,lay_ind]==2,time_ind][0]-T_M)\n",
    "                sub_ev[mask,t0_2_ind] = 0.5*(0.5*(sub_ev[sub_ev[mask,lay_ind]==2,time_ind][0]+\n",
    "                                           sub_ev[sub_ev[mask,lay_ind]==4,time_ind][0])+\n",
    "                                      sub_ev[sub_ev[mask,lay_ind]==3,time_ind][0]-T_M)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_t0(df, numba_optimized=True):\n",
    "    events = df.copy(deep=False)\n",
    "\n",
    "    if not numba_optimized:\n",
    "        events = findTrajectories(events)\n",
    "\n",
    "    else:\n",
    "        events['t0_123'] = 0\n",
    "        events['t0_234'] = 0\n",
    "        level0_inds = events.index.get_level_values(0).to_numpy()\n",
    "        c_names = ['detector', 'layer', 'cell', 'time', 't0_123', 't0_234']\n",
    "        columns = np.array([events.columns.get_loc(column) for column in c_names])\n",
    "\n",
    "        data = findTrajectories_np(events.to_numpy(), level0_inds, columns)\n",
    "        events = pd.DataFrame(data=data, index=events.index, columns=events.columns)\n",
    "\n",
    "        events['detector'] = events['detector'].astype(np.int32)\n",
    "        events['layer'] = events['layer'].astype(np.int32)\n",
    "        events['cell'] = events['cell'].astype(np.int32)\n",
    "\n",
    "    return events\n",
    "\n",
    "events_mtt = calculate_t0(events_mtt)\n",
    "display(events_mtt.head(5))\n",
    "if not trigger_st.empty:\n",
    "    events_st = calculate_t0(events_st)\n",
    "    display(events_st.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id =5></a><br> 'VISUALIZING' THE EVENTS\n",
    " [Content Outline](#6)\n",
    "## <span style='color:  gray'> CALCULATION OF DRIFT TIMES </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hist(df):\n",
    "    events = df.copy(deep=False)\n",
    "\n",
    "    events['drift_time'] = events['time'] - events['t0_123'] # use one t0???\n",
    "    events['x'] = v_d*events['drift_time']\n",
    "    # Clean up data for events which have a negative drift time or a position over 21mm\n",
    "    events.loc[(events['drift_time']<0) | (events['x']>L/2), 't0_123'] = np.nan\n",
    "\n",
    "    events.loc[events['t0_123'].notna(),'drift_time'].plot(kind='hist', title='Distribution of Drift Times',\n",
    "                             bins=100) # driftime instead of x???\n",
    "\n",
    "    plt.xlabel('Drift time (ns)')\n",
    "    plt.ylabel('Number of Occurrences')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    printmd('#### Remark: the maximum amount of occurences happen around 10 mm from the anodic wire.')\n",
    "    \n",
    "    return events\n",
    "\n",
    "\n",
    "display(events_mtt.head(5))\n",
    "events_mtt = make_hist(events_mtt)\n",
    "if not trigger_st.empty:\n",
    "    events_st = make_hist(events_st)\n",
    "    display(events_st.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:  gray'> FILTERING THE DATA </span>\n",
    "\n",
    "###  Useful events: showing the percentage of events that have more than 3 hits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_useful_events(df):\n",
    "    events = df.copy(deep=False)\n",
    "\n",
    "    # Ratio of \"useful events\" to all events\n",
    "    try:\n",
    "        print('\"useful rows\" / \"all rows\": ', 1 - len(events[events['t0_123'].isna()])/events.shape[0])\n",
    "    except ZeroDivisionError:\n",
    "        print('Error: Dataframe is empty')\n",
    "\n",
    "    # Event is counted as useful if 4 or more times are available\n",
    "    event_groups = events.loc[~events['t0_123'].isna(),'time'].groupby('event').count()\n",
    "    # print(event_groups) \n",
    "    try:\n",
    "        print('\"useful events\" / \"all events\"', (event_groups>3).sum()/len(event_groups))  # some events only have 3 (or below) hits\n",
    "    except ZeroDivisionError:\n",
    "        print('Error: Dataframe is empty')\n",
    "\n",
    "\n",
    "print('Mean Time Trigger:')\n",
    "print_useful_events(events_mtt)\n",
    "if not trigger_st.empty:\n",
    "    print('Scintillator Trigger')\n",
    "    print_useful_events(events_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter 2: Drop hits that do not align\n",
    "### Filter 3: Obtain events that have at least one hit per layer (i.e. 4 layer representation)\n",
    "### Filter 4: Sort OUT events that have only ONE detector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_vis(df):\n",
    "    # Drop all not aligning hits\n",
    "    visual_evs = df.dropna(subset=['t0_123']).copy() # subset = array which limits the dropping process to passed rows/columns through list.\n",
    "\n",
    "    # Sort out events which are not in every layer, each event must have 4 layers\n",
    "    go_through_each_lay = visual_evs.loc[:,'layer'].groupby(level=0).nunique() == 4\n",
    "\n",
    "    # Sort out events which are only registered in one detector\n",
    "    go_through_each_lay = (visual_evs.loc[:,['layer','detector']].groupby(['event','detector']).nunique() == 4).loc[:,'layer']\n",
    "    go_through_each_lay = go_through_each_lay.groupby('event').all()\n",
    "    # Sort out events which are only registered in one detector\n",
    "    multiple_detectors = visual_evs.loc[:,'detector'].groupby('event').nunique() > 1\n",
    "    # Combine the two masks\n",
    "    index_mask = go_through_each_lay & multiple_detectors\n",
    "\n",
    "    # Apply it to dataframe\n",
    "    visual_evs = visual_evs.loc[visual_evs.index.get_level_values(0).map(index_mask),:]\n",
    "\n",
    "    # Reindex the event index level starting from 1\n",
    "    visual_evs.reset_index(level='event', inplace=True)\n",
    "    visual_evs.loc[:,'event'] = (visual_evs.loc[:,'event'].diff()!=0).cumsum()\n",
    "    visual_evs.set_index(['event', visual_evs.index], inplace=True)\n",
    "    \n",
    "    return visual_evs\n",
    "\n",
    "\n",
    "events_mtt_vis = prepare_for_vis(events_mtt)\n",
    "display(events_mtt_vis.head(4))\n",
    "if not trigger_st.empty:\n",
    "    events_st_vis = prepare_for_vis(events_st)\n",
    "    display(events_st_vis.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a id =7></a><br> <span style='color:  gray'> MAKING THE DETECTOR MATRIX </span>\n",
    " [Content Outline](#6)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(\"### Event Data\")\n",
    "def plotDetector(ax, event, is_empty):\n",
    "    detector = np.zeros((4,16*2+1))\n",
    "\n",
    "    even_layers = event['layer']%2 == 0\n",
    "    odd_layers = even_layers == False\n",
    "\n",
    "    def fillDetectorMatrix(matrix, i, j, s=0):\n",
    "        matrix[i,j*2+s] = 1\n",
    "        matrix[i,j*2+1+s] = 1\n",
    "\n",
    "    def plotLeftRight(ax, cell, position, layer, odd, left):\n",
    "        if left == True:\n",
    "            ax.scatter((cell-1-position/L)*2+0.5+odd, layer-1, s=10, c='g', marker='+')\n",
    "        else:\n",
    "            ax.scatter((cell-1+position/L)*2+0.5+odd, layer-1, s=10, c='b', marker='+')\n",
    "    \n",
    "    if is_empty == False:\n",
    "        fillDetectorMatrix(detector, event.loc[even_layers,'layer']-1,\n",
    "                    event.loc[even_layers,'cell']-1, s=0)\n",
    "        fillDetectorMatrix(detector, event.loc[odd_layers,'layer']-1,\n",
    "                    event.loc[odd_layers,'cell']-1, s=1)\n",
    "\n",
    "        for odd,left in [[odd, left] for odd in [True, False] for left in [True,False]]:\n",
    "            if odd == True:\n",
    "                layers = odd_layers\n",
    "            else:\n",
    "                layers = even_layers\n",
    "\n",
    "            plotLeftRight(ax, event.loc[layers, 'cell'], event.loc[layers, 'x'],\n",
    "                     event.loc[layers, 'layer'], odd, left)\n",
    "\n",
    "    detector[(0,1,2,3),(0,32,0,32)] = 0.5 # Mark \"cell offset\"\n",
    "    ax.matshow(detector, origin='lower', cmap='bone', vmin=0, vmax=1)\n",
    "\n",
    "    # Major ticks\n",
    "    ax.set_xticks(np.arange(1.5, 32, 2));\n",
    "    ax.set_yticks(np.arange(0, 4, 1));\n",
    "\n",
    "    # # Labels for major ticks\n",
    "    ax.set_xticklabels(np.arange(1, 17, 1));\n",
    "    ax.set_yticklabels(np.arange(1, 5, 1));\n",
    "\n",
    "    # # Minor ticks\n",
    "    # # ax.set_xticks(np.arange(-.5, 32, 2), minor=True);\n",
    "    ax.set_yticks(np.arange(0.5, 4, 1), minor=True);\n",
    "\n",
    "    ax.grid(which='minor', axis='y', color='w', linewidth=1)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    vert_line = np.array([0,1])\n",
    "    for l in range(4):\n",
    "        for c in range(16):\n",
    "            if l%2 == 0:\n",
    "                ax.plot([c*2+0.5,c*2+0.5], vert_line+l-0.5, c='w')\n",
    "            else:\n",
    "                ax.plot([c*2+1.5,c*2+1.5], vert_line+l-0.5, c='w')\n",
    "\n",
    "def plotEvent(event):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12,4))\n",
    "\n",
    "    for i in range(0,4):\n",
    "        sub_ev = event.loc[event['detector']==i+1, :]\n",
    "        plotDetector(axes[1-i%2,i//2], sub_ev, sub_ev.empty)\n",
    "        axes[1-i%2,i//2].set_title('Detector {}'.format(i+1))\n",
    "    # TODO legend\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "printmd('Blue dots indicate paths at the right of the anodic wire, Green dots indicate paths at the left as in the project description')\n",
    "printmd(\"### Event Path 1\")\n",
    "plotEvent(events_mtt_vis.loc[47])\n",
    "\n",
    "printmd(\"### Event Path 2\")\n",
    "plotEvent(events_mtt_vis.loc[500])\n",
    "\n",
    "printmd(\"### Event Path 3\")\n",
    "plotEvent(events_mtt_vis.loc[450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
